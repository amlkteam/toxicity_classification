{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigsaw_6classesinOne.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "047416b1dbfd464ab3e7c29eb98556a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_285d1d5b5a614134a2ad1e426a255209",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3447ae30fdd6458fa83d130dc5a0e086",
              "IPY_MODEL_88e545d1bb6f4e26bffc30a833151b31"
            ]
          }
        },
        "285d1d5b5a614134a2ad1e426a255209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3447ae30fdd6458fa83d130dc5a0e086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c660ac7289a4097934f9bf92b26ad5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb4a99477d6e49049a27b9af34597341"
          }
        },
        "88e545d1bb6f4e26bffc30a833151b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87309e238575472ca8d76b367290a0a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 621kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_490a0a0db9f94c2c9befe9ad89e06746"
          }
        },
        "5c660ac7289a4097934f9bf92b26ad5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb4a99477d6e49049a27b9af34597341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87309e238575472ca8d76b367290a0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "490a0a0db9f94c2c9befe9ad89e06746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c1d29a82d904230a154417852a97391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c8c2764e27f4b28b982d8e08d721d13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_559521d8b0144207936afbb289370b83",
              "IPY_MODEL_91127a2f082048fd962d5e9e4b23c5cf"
            ]
          }
        },
        "2c8c2764e27f4b28b982d8e08d721d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "559521d8b0144207936afbb289370b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2eeb0a4cc0184829b440f070a6ea2c55",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ad1ed30a1d44c289ff1514a3d5e088d"
          }
        },
        "91127a2f082048fd962d5e9e4b23c5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7816b1c79aa4a02b2927505ddb0a4b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:16&lt;00:00, 22.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a464153765b1445bad65d6cda425f79d"
          }
        },
        "2eeb0a4cc0184829b440f070a6ea2c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ad1ed30a1d44c289ff1514a3d5e088d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7816b1c79aa4a02b2927505ddb0a4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a464153765b1445bad65d6cda425f79d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c331c4fd981442319ee1de9ae5ebdd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_444e854ebc934b73851e535c2e658692",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9f0e6ad5c8f406d847d21865304adc8",
              "IPY_MODEL_caa3debe71bf41aaad47a37827d32e01"
            ]
          }
        },
        "444e854ebc934b73851e535c2e658692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9f0e6ad5c8f406d847d21865304adc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4207bb298a074a34aa5adf02efa7b859",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83f9b05f4206450bbf4b9d8454fe0d46"
          }
        },
        "caa3debe71bf41aaad47a37827d32e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3da712ba906744b3a7e2e63e73af51c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:15&lt;00:00, 28.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e95ec9ec11c4bc089b7daddb1d3da47"
          }
        },
        "4207bb298a074a34aa5adf02efa7b859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83f9b05f4206450bbf4b9d8454fe0d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3da712ba906744b3a7e2e63e73af51c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e95ec9ec11c4bc089b7daddb1d3da47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxjoTpYDTNkB",
        "colab_type": "code",
        "outputId": "1c874285-0f95-4a4d-8a85-521d63978ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "!pip install transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 10.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 58.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=228f60de22e9c602333a80723d5e7174577cf0d1a9360c2db99cbaa7b0348fa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u6oatPXTzvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## hyperparameters\n",
        "\n",
        "# • Batch size: 16, 32\n",
        "# • Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "# • Number of epochs: 2, 3, 4\n",
        "\n",
        "### using batch size 16\n",
        "# other configs\n",
        "\n",
        "# Epoch 1 | Loss - 225.45395208522677 | Time Taken - 6.68 min\n",
        "# Macro F1 Score 0.9066872060512802\n",
        "# Macro F1 Score 0.9067430138165765"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG0geZTuTVv4",
        "colab_type": "code",
        "outputId": "366e3ec2-e16b-445a-a722-8bf4d642a72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "047416b1dbfd464ab3e7c29eb98556a9",
            "285d1d5b5a614134a2ad1e426a255209",
            "3447ae30fdd6458fa83d130dc5a0e086",
            "88e545d1bb6f4e26bffc30a833151b31",
            "5c660ac7289a4097934f9bf92b26ad5c",
            "bb4a99477d6e49049a27b9af34597341",
            "87309e238575472ca8d76b367290a0a9",
            "490a0a0db9f94c2c9befe9ad89e06746",
            "5c1d29a82d904230a154417852a97391",
            "2c8c2764e27f4b28b982d8e08d721d13",
            "559521d8b0144207936afbb289370b83",
            "91127a2f082048fd962d5e9e4b23c5cf",
            "2eeb0a4cc0184829b440f070a6ea2c55",
            "3ad1ed30a1d44c289ff1514a3d5e088d",
            "c7816b1c79aa4a02b2927505ddb0a4b2",
            "a464153765b1445bad65d6cda425f79d",
            "c331c4fd981442319ee1de9ae5ebdd1e",
            "444e854ebc934b73851e535c2e658692",
            "f9f0e6ad5c8f406d847d21865304adc8",
            "caa3debe71bf41aaad47a37827d32e01",
            "4207bb298a074a34aa5adf02efa7b859",
            "83f9b05f4206450bbf4b9d8454fe0d46",
            "3da712ba906744b3a7e2e63e73af51c0",
            "3e95ec9ec11c4bc089b7daddb1d3da47"
          ]
        }
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import logging\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "model_class = transformers.BertModel\n",
        "tokenizer_class = transformers.BertTokenizer\n",
        "pretrained_weights='bert-base-uncased'\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "bert_model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/jigsaw/train/'\n",
        "df = pd.read_csv(data_path + 'train.csv')\n",
        "df = df.drop(['id'], axis = 1)\n",
        "df = df.sample(frac=1, random_state = 42)\n",
        "\n",
        "toxic = df[df.toxic == 1]\n",
        "non_toxic = df[df.toxic != 1]\n",
        "non_toxic = non_toxic.sample(n = 15000)\n",
        "df = pd.concat([toxic, non_toxic])\n",
        "df = df.sample(frac=1, random_state = 42)\n",
        "\n",
        "train, val, test = df[:20000].values, df[20000:25000].values, df[25000:].values\n",
        "print('Train Size', train.shape)\n",
        "print('Val Size', val.shape)\n",
        "print('Test Size', test.shape)\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, dataframe, max_len):\n",
        "        self.dataframe = dataframe\n",
        "        self.max_len = max_len\n",
        "        self.sep_id = tokenizer.encode(['[SEP]'], add_special_tokens=False)\n",
        "        self.pad_id = tokenizer.encode(['[PAD]'], add_special_tokens=False)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe[idx]\n",
        "        text = row[0]\n",
        "        #targets = torch.tensor(list(row[1:]))\n",
        "        encoded = tokenizer.encode(text, add_special_tokens=True)[:self.max_len-1]\n",
        "        if encoded[-1] != self.sep_id[0]:\n",
        "            encoded = encoded + self.sep_id\n",
        "        padded = encoded + self.pad_id * (self.max_len - len(encoded))\n",
        "        padded = torch.tensor(padded)\n",
        "        labels = torch.Tensor(list(row[1:]))\n",
        "        return padded, labels\n",
        "\n",
        "\n",
        "train_dataset = ToxicDataset(train, 84) # why set max-length to 84? longer better or worse?\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "val_dataset = ToxicDataset(val, 84)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "test_dataset = ToxicDataset(test, 84)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "def evaluate(model, data):\n",
        "    actual, predictions = [], []\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data:\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "            scores, attentions = model(features)\n",
        "            sigmoid_out = torch.sigmoid(scores)\n",
        "            prediction = torch.as_tensor(sigmoid_out > 0.6, dtype=torch.int32) #changing to 0.6 to get more confident predictions to be \"1\" -- not much diff\n",
        "            predictions.extend(prediction.view(-1).tolist())\n",
        "            actual.extend(targets.long().view(-1).tolist())\n",
        "    assert len(actual) == len(predictions)\n",
        "    print('Macro F1 Score', f1_score(actual, predictions, average = 'macro'))\n",
        "\n",
        "class BertNN(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BertNN, self).__init__()\n",
        "        self.bert_model = transformers.BertModel.from_pretrained(pretrained_weights, output_attentions = True)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(hidden_size, 6)\n",
        "\n",
        "    def forward(self, ex):\n",
        "        _, pooled_output, attentions = self.bert_model(ex)\n",
        "        #pooled_output = self.dropout(pooled_output) #why dropout after model output? -- lower scores without dropout of 0.1\n",
        "        fc_out = self.fc(pooled_output)\n",
        "        return fc_out, attentions\n",
        "\n",
        "\n",
        "model = BertNN(768)\n",
        "model = model.to(device)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "loss_function = loss_function.to(device)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "047416b1dbfd464ab3e7c29eb98556a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c1d29a82d904230a154417852a97391",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c331c4fd981442319ee1de9ae5ebdd1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Size (20000, 7)\n",
            "Val Size (5000, 7)\n",
            "Test Size (5294, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5yXX5M5dram",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lrs = [5e-5, 3e-5, 2e-5]\n",
        "# epochs = [2,3,4]\n",
        "\n",
        "# for lrate in lrs:\n",
        "#   for ep in epochs:\n",
        "\n",
        "#     print(\"------------------------------\")\n",
        "#     print(\"---learning_rate:\",lrate,\"---epoch number:\",ep)\n",
        "\n",
        "#     optimizer = transformers.AdamW(model.parameters(), lr=lrate, correct_bias=False)\n",
        "#     MAX_EPOCHS = ep\n",
        "\n",
        "#     max_grad_norm = 1.0\n",
        "#     warmup_proportion = 0.1\n",
        "#     num_training_steps  = len(train_dataloader) * MAX_EPOCHS\n",
        "#     num_warmup_steps = num_training_steps * warmup_proportion\n",
        "#     scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "#     for epoch in range(MAX_EPOCHS):\n",
        "#         epoch_loss = 0\n",
        "#         start_time = time.time()\n",
        "#         for idx, (features, targets) in enumerate(train_dataloader):\n",
        "#             model.zero_grad()\n",
        "#             features = features.to(device)\n",
        "#             targets = targets.to(device)\n",
        "#             scores, attentions = model(features)\n",
        "#             loss = loss_function(scores, targets)\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "#             epoch_loss += loss.item()\n",
        "#         if device == 'cuda':\n",
        "#             torch.cuda.empty_cache()\n",
        "#         time_taken = round((time.time() - start_time)/60, 2)\n",
        "#         print(f'Epoch {epoch + 1} | Loss - {epoch_loss} | Time Taken - {time_taken} min')\n",
        "#         evaluate(model, val_dataloader)\n",
        "\n",
        "#     evaluate(model, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3sDh55-qgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #optimize on other hyperparameters with best config (Batch_size 32, Num_epochs 2 and learning rate 2e-5) at 0.9065)\n",
        "\n",
        "# grad_caps = [0.7,0.8,0.9,1.0,1.1]\n",
        "# warmup_props = [0.05,0.1,0.15,0.20]\n",
        "\n",
        "# for grad_cap in grad_caps:\n",
        "#   for wp in warmup_props:\n",
        "\n",
        "#     print(\"------------------------------\")\n",
        "#     print(\"grad_cap: \",grad_cap,\"warmup ratio:\",wp)\n",
        "\n",
        "#     optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "#     MAX_EPOCHS = 2\n",
        "\n",
        "#     max_grad_norm = grad_cap\n",
        "#     warmup_proportion = wp\n",
        "#     num_training_steps  = len(train_dataloader) * MAX_EPOCHS\n",
        "#     num_warmup_steps = num_training_steps * warmup_proportion\n",
        "#     scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "#     for epoch in range(MAX_EPOCHS):\n",
        "#         epoch_loss = 0\n",
        "#         start_time = time.time()\n",
        "#         for idx, (features, targets) in enumerate(train_dataloader):\n",
        "#             model.zero_grad()\n",
        "#             features = features.to(device)\n",
        "#             targets = targets.to(device)\n",
        "#             scores, attentions = model(features)\n",
        "#             loss = loss_function(scores, targets)\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "#             epoch_loss += loss.item()\n",
        "#         if device == 'cuda':\n",
        "#             torch.cuda.empty_cache()\n",
        "#         time_taken = round((time.time() - start_time)/60, 2)\n",
        "#         print(f'Epoch {epoch + 1} | Loss - {epoch_loss} | Time Taken - {time_taken} min')\n",
        "#         evaluate(model, val_dataloader)\n",
        "\n",
        "#     evaluate(model, test_dataloader)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEI7-DeQOH3C",
        "colab_type": "text"
      },
      "source": [
        "------------------------------\n",
        "---learning_rate: 5e-05 ---epoch number: 2\n",
        "Epoch 1 | Loss - 185.50375414825976 | Time Taken - 6.71 min\n",
        "Macro F1 Score 0.9021034695669485\n",
        "Epoch 2 | Loss - 114.24120777100325 | Time Taken - 6.74 min\n",
        "Macro F1 Score 0.906154007852682\n",
        "Macro F1 Score 0.9039604591274064\n",
        "------------------------------\n",
        "---learning_rate: 5e-05 ---epoch number: 3\n",
        "Epoch 1 | Loss - 113.86767609696835 | Time Taken - 6.76 min\n",
        "Macro F1 Score 0.8980777158201751\n",
        "Epoch 2 | Loss - 68.56986253336072 | Time Taken - 6.76 min\n",
        "Macro F1 Score 0.9024997447787437\n",
        "Epoch 3 | Loss - 25.431545083178207 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.9007347184115244\n",
        "Macro F1 Score 0.9004183493704224\n",
        "------------------------------\n",
        "---learning_rate: 5e-05 ---epoch number: 4\n",
        "Epoch 1 | Loss - 48.0631898221327 | Time Taken - 6.76 min\n",
        "Macro F1 Score 0.8937235058912867\n",
        "Epoch 2 | Loss - 38.893465779023245 | Time Taken - 6.76 min\n",
        "Macro F1 Score 0.8974896086979957\n",
        "Epoch 3 | Loss - 15.807909779017791 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.899546218039083\n",
        "Epoch 4 | Loss - 6.546204233251046 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.8987044518742549\n",
        "Macro F1 Score 0.898889561924533\n",
        "------------------------------\n",
        "---learning_rate: 3e-05 ---epoch number: 2\n",
        "Epoch 1 | Loss - 17.139940027467674 | Time Taken - 6.73 min\n",
        "Macro F1 Score 0.8979094940390212\n",
        "Epoch 2 | Loss - 9.797589176683687 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.8999239356644051\n",
        "Macro F1 Score 0.8986270303938924\n",
        "------------------------------\n",
        "---learning_rate: 3e-05 ---epoch number: 3\n",
        "Epoch 1 | Loss - 15.056858391268179 | Time Taken - 6.72 min\n",
        "Macro F1 Score 0.8969136549962933\n",
        "Epoch 2 | Loss - 9.885369804294896 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.8971041623284735\n",
        "Epoch 3 | Loss - 3.5665759591938695 | Time Taken - 6.67 min\n",
        "Macro F1 Score 0.898433945807134\n",
        "Macro F1 Score 0.895936492822745\n",
        "------------------------------\n",
        "---learning_rate: 3e-05 ---epoch number: 4\n",
        "Epoch 1 | Loss - 11.83489630351687 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.8945012660625431\n",
        "Epoch 2 | Loss - 11.014763164821488 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.8944186703686314\n",
        "Epoch 3 | Loss - 4.102971798660292 | Time Taken - 6.68 min\n",
        "Macro F1 Score 0.8956924293696304\n",
        "Epoch 4 | Loss - 1.98880013687085 | Time Taken - 6.66 min\n",
        "Macro F1 Score 0.8967334020570794\n",
        "Macro F1 Score 0.8978343413588961\n",
        "------------------------------\n",
        "---learning_rate: 2e-05 ---epoch number: 2\n",
        "Epoch 1 | Loss - 5.756832868690253 | Time Taken - 6.68 min\n",
        "Macro F1 Score 0.8938565575963329\n",
        "Epoch 2 | Loss - 3.615225807436218 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.8972600945110007\n",
        "Macro F1 Score 0.8995537473728882\n",
        "------------------------------\n",
        "---learning_rate: 2e-05 ---epoch number: 3\n",
        "Epoch 1 | Loss - 6.122836466758599 | Time Taken - 6.71 min\n",
        "Macro F1 Score 0.8950945192781365\n",
        "Epoch 2 | Loss - 4.057592681296228 | Time Taken - 6.7 min\n",
        "Macro F1 Score 0.8981179267253738\n",
        "Epoch 3 | Loss - 1.6067845029756427 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.8990145960456842\n",
        "Macro F1 Score 0.8965980383958093\n",
        "------------------------------\n",
        "---learning_rate: 2e-05 ---epoch number: 4\n",
        "Epoch 1 | Loss - 5.862004778915434 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.8948865503358773\n",
        "Epoch 2 | Loss - 3.9814947778468195 | Time Taken - 6.69 min\n",
        "Macro F1 Score 0.8974067506347232\n",
        "Epoch 3 | Loss - 1.9183375269894896 | Time Taken - 6.68 min\n",
        "Macro F1 Score 0.8980227122152622\n",
        "Epoch 4 | Loss - 1.2592462805005198 | Time Taken - 6.67 min\n",
        "Macro F1 Score 0.8988635298473914\n",
        "Macro F1 Score 0.8941328374758069"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv3q7Uzucj9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##finetuning result on 2 other hyperparameter\n",
        "\n",
        "# ------------------------------\n",
        "# grad_cap:  0.7 warmup ratio: 0.05\n",
        "# Epoch 1 | Loss - 107.26633888110518 | Time Taken - 5.68 min\n",
        "# Macro F1 Score 0.8936619260990974\n",
        "# Epoch 2 | Loss - 67.15605465695262 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9034971220810166\n",
        "# Macro F1 Score 0.9050485248498495\n",
        "# ------------------------------\n",
        "# grad_cap:  0.7 warmup ratio: 0.1\n",
        "# Epoch 1 | Loss - 64.63833036273718 | Time Taken - 5.76 min\n",
        "# Macro F1 Score 0.8929998575593225\n",
        "# Epoch 2 | Loss - 37.07104470767081 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9043445927002802\n",
        "# Macro F1 Score 0.9031651974293001\n",
        "# ------------------------------\n",
        "# grad_cap:  0.7 warmup ratio: 0.15\n",
        "# Epoch 1 | Loss - 34.45320533961058 | Time Taken - 5.76 min\n",
        "# Macro F1 Score 0.901797099109847\n",
        "# Epoch 2 | Loss - 19.692186129279435 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9037087511495988\n",
        "# Macro F1 Score 0.9014698830043779\n",
        "# ------------------------------\n",
        "# grad_cap:  0.7 warmup ratio: 0.2\n",
        "# Epoch 1 | Loss - 18.475861214334145 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.8971559825114002\n",
        "# Epoch 2 | Loss - 10.991576835745946 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.902774639754621\n",
        "# Macro F1 Score 0.8991474259894763\n",
        "# ------------------------------\n",
        "# grad_cap:  0.8 warmup ratio: 0.05\n",
        "# Epoch 1 | Loss - 15.10654376912862 | Time Taken - 5.75 min\n",
        "# Macro F1 Score 0.9001843533731848\n",
        "# Epoch 2 | Loss - 7.48791551287286 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9028398845845602\n",
        "# Macro F1 Score 0.9009134450233417\n",
        "# ------------------------------\n",
        "# grad_cap:  0.8 warmup ratio: 0.1\n",
        "# Epoch 1 | Loss - 10.374420619104058 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9030680250145007\n",
        "# Epoch 2 | Loss - 6.229179871734232 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9047617384038483\n",
        "# Macro F1 Score 0.899292643921745\n",
        "# ------------------------------\n",
        "# grad_cap:  0.8 warmup ratio: 0.15\n",
        "# Epoch 1 | Loss - 8.383389445574721 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9013340069201947\n",
        "# Epoch 2 | Loss - 5.001985712442547 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9020593471919256\n",
        "# Macro F1 Score 0.8999045018715068\n",
        "# ------------------------------\n",
        "# grad_cap:  0.8 warmup ratio: 0.2\n",
        "# Epoch 1 | Loss - 6.650678715726826 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.8994794706569655\n",
        "# Epoch 2 | Loss - 4.880266388820019 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9011177477805938\n",
        "# Macro F1 Score 0.8997392516797682\n",
        "# ------------------------------\n",
        "# grad_cap:  0.9 warmup ratio: 0.05\n",
        "# Epoch 1 | Loss - 8.720274956838693 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.9018977326508155\n",
        "# Epoch 2 | Loss - 4.395385441632243 | Time Taken - 5.71 min\n",
        "# Macro F1 Score 0.9040334973922209\n",
        "# Macro F1 Score 0.9012246193274818\n",
        "# ------------------------------\n",
        "# grad_cap:  0.9 warmup ratio: 0.1\n",
        "# Epoch 1 | Loss - 7.5400077268714085 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9009305656784353\n",
        "# Epoch 2 | Loss - 3.6871492758218665 | Time Taken - 5.71 min\n",
        "# Macro F1 Score 0.9019291870695412\n",
        "# Macro F1 Score 0.8985438406056665\n",
        "# ------------------------------\n",
        "# grad_cap:  0.9 warmup ratio: 0.15\n",
        "# Epoch 1 | Loss - 5.497639556037029 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.8982489473866462\n",
        "# Epoch 2 | Loss - 2.7703927679976914 | Time Taken - 5.71 min\n",
        "# Macro F1 Score 0.8992530032252194\n",
        "# Macro F1 Score 0.8982796102199433\n",
        "# ------------------------------\n",
        "# grad_cap:  0.9 warmup ratio: 0.2\n",
        "# Epoch 1 | Loss - 4.724318902663072 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.9006461370985697\n",
        "# Epoch 2 | Loss - 3.402612740181212 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9031339112406707\n",
        "# Macro F1 Score 0.8995456641791317\n",
        "# ------------------------------\n",
        "# grad_cap:  1.0 warmup ratio: 0.05\n",
        "# Epoch 1 | Loss - 7.131069630733691 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9000607861865744\n",
        "# Epoch 2 | Loss - 2.9061441709054634 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9021898976006097\n",
        "# Macro F1 Score 0.9006945421406302\n",
        "# ------------------------------\n",
        "# grad_cap:  1.0 warmup ratio: 0.1\n",
        "# Epoch 1 | Loss - 5.95309567694494 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.8998067655583233\n",
        "# Epoch 2 | Loss - 2.511273366457317 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.903417640991338\n",
        "# Macro F1 Score 0.9008547674938299\n",
        "# ------------------------------\n",
        "# grad_cap:  1.0 warmup ratio: 0.15\n",
        "# Epoch 1 | Loss - 4.612910380543326 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.8989332171786292\n",
        "# Epoch 2 | Loss - 2.9027357136656065 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.9021860735986387\n",
        "# Macro F1 Score 0.900064222790183\n",
        "# ------------------------------\n",
        "# grad_cap:  1.0 warmup ratio: 0.2\n",
        "# Epoch 1 | Loss - 4.000405219419918 | Time Taken - 5.75 min\n",
        "# Macro F1 Score 0.8978901432459965\n",
        "# Epoch 2 | Loss - 2.5934266846670653 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.9005788494435067\n",
        "# Macro F1 Score 0.8997090852576312\n",
        "# ------------------------------\n",
        "# grad_cap:  1.1 warmup ratio: 0.05\n",
        "# Epoch 1 | Loss - 6.177263775025494 | Time Taken - 5.76 min\n",
        "# Macro F1 Score 0.8990900582253667\n",
        "# Epoch 2 | Loss - 2.3012431833485607 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.9009714978994641\n",
        "# Macro F1 Score 0.8997612023395669\n",
        "# ------------------------------\n",
        "# grad_cap:  1.1 warmup ratio: 0.1\n",
        "# Epoch 1 | Loss - 4.6941000642837025 | Time Taken - 5.75 min\n",
        "# Macro F1 Score 0.9004683030924514\n",
        "# Epoch 2 | Loss - 2.2402445025072666 | Time Taken - 5.73 min\n",
        "# Macro F1 Score 0.9016907040025756\n",
        "# Macro F1 Score 0.8979497807415765\n",
        "# ------------------------------\n",
        "# grad_cap:  1.1 warmup ratio: 0.15\n",
        "# Epoch 1 | Loss - 4.88284892111551 | Time Taken - 5.74 min\n",
        "# Macro F1 Score 0.8997517563870083\n",
        "# Epoch 2 | Loss - 2.217922415533394 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.9007822324817372\n",
        "# Macro F1 Score 0.897922467059006\n",
        "# ------------------------------\n",
        "# grad_cap:  1.1 warmup ratio: 0.2\n",
        "# Epoch 1 | Loss - 3.752467484206136 | Time Taken - 5.72 min\n",
        "# Macro F1 Score 0.8996026403701827\n",
        "# Epoch 2 | Loss - 1.9224082648433978 | Time Taken - 5.71 min\n",
        "# Macro F1 Score 0.8997154477950396\n",
        "# Macro F1 Score 0.8987948909936838"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBvDdlTjedJ7",
        "colab_type": "code",
        "outputId": "505d516d-d6e1-441b-b804-76c6900ce416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "\n",
        "# best model\n",
        "# with grad_cap:  0.7 warmup ratio: 0.05 from best test acc  ==>testset Macro F1 Score 0.9050637842441922\n",
        "## with original grad_cap and warmup ratio-- test score 0.9008\n",
        "\n",
        "## best result after bestcombo -- test Macro F1 Score 0.9063973462017885\n",
        "\n",
        "optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "MAX_EPOCHS = 2\n",
        "\n",
        "max_grad_norm = 0.7\n",
        "warmup_proportion = 0.05\n",
        "num_training_steps  = len(train_dataloader) * MAX_EPOCHS\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    start_time = time.time()\n",
        "    for idx, (features, targets) in enumerate(train_dataloader):\n",
        "        model.zero_grad()\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "        scores, attentions = model(features)\n",
        "        loss = loss_function(scores, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.item()\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "    time_taken = round((time.time() - start_time)/60, 2)\n",
        "    print(f'Epoch {epoch + 1} | Loss - {epoch_loss} | Time Taken - {time_taken} min')\n",
        "    evaluate(model, val_dataloader)\n",
        "\n",
        "    evaluate(model, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss - 116.66352342069149 | Time Taken - 3.0 min\n",
            "Macro F1 Score 0.9005833317962711\n",
            "Macro F1 Score 0.9056820254954276\n",
            "Epoch 2 | Loss - 68.99307287856936 | Time Taken - 3.0 min\n",
            "Macro F1 Score 0.9025019635208984\n",
            "Macro F1 Score 0.9063973462017885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfooyYpdUyuG",
        "colab_type": "code",
        "outputId": "fd11067f-84e3-4a4e-c5b2-2e0de42a15a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "data = test_dataloader\n",
        "\n",
        "actual, predictions = [], []\n",
        "with torch.no_grad():\n",
        "    for features, targets in data:\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "        scores, attentions = model(features)\n",
        "        sigmoid_out = torch.sigmoid(scores)\n",
        "        prediction = torch.as_tensor(sigmoid_out > 0.5, dtype=torch.int32)\n",
        "\n",
        "        print(features)\n",
        "        print(targets)\n",
        "        print(prediction.view(-1).tolist())\n",
        "        break\n",
        "#         predictions.extend(prediction.view(-1).tolist())\n",
        "#         actual.extend(targets.long().view(-1).tolist())\n",
        "# assert len(actual) == len(predictions)\n",
        "# print('Macro F1 Score', f1_score(actual, predictions, average = 'macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  3531,  5607,  ...,     0,     0,     0],\n",
            "        [  101,  2036,  1010,  ...,     0,     0,     0],\n",
            "        [  101,  2017, 11891,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1000,  3241,  ...,  2033,  2065,   102],\n",
            "        [  101,  1005,  1005,  ...,  1005,  1005,   102],\n",
            "        [  101,  2026, 12997,  ...,     0,     0,     0]], device='cuda:0')\n",
            "tensor([[1., 0., 1., 1., 1., 0.],\n",
            "        [1., 0., 0., 0., 1., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 1., 0.],\n",
            "        [1., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C07n9heQZmKE",
        "colab_type": "code",
        "outputId": "856e3b0f-93e9-449c-ecee-2128a862e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(prediction)\n",
        "prediction[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 1, 0, 0], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdT0Dx3iUxzJ",
        "colab_type": "code",
        "outputId": "0803ecff-597c-4b79-9824-24c333310637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, feat in enumerate(features):\n",
        "  #print(tokenizer.convert_ids_to_tokens(feat))\n",
        "  full_strs = tokenizer.convert_ids_to_tokens(feat)\n",
        "\n",
        "  full_str = ''\n",
        "  for strs in full_strs:\n",
        "    if strs not in ['[PAD]','[SEP]','[CLS]']:\n",
        "      full_str += strs + \" \"\n",
        "  print(full_str)\n",
        "\n",
        "  print(prediction[i])\n",
        "  print(targets[i])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "please shoot yourself please put yourself out of your misery . either shoot or hang yourself you depressed freak . \n",
            "tensor([1, 0, 0, 1, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 1., 1., 0.], device='cuda:0')\n",
            "also , my mother is a prostitute who loves her black pi ##mp . \n",
            "tensor([1, 0, 0, 0, 1, 1], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 1., 0.], device='cuda:0')\n",
            "you suck hardcore yep you heard it \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
            "\" honestly ? you all get your pages to talk about your railroad fe ##tish and your \" \" awards \" \" , but when so ##mon ##e actually does something real , and someone wants to bring attention to that persons accomplishments , you ne ##rds attempt to block it ? this is communist . \" \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am a bad egg i am \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "this was placed here because this user is a liar who has broken 3 ##rr numerous times , a few days straight in a row . that he chooses to attack me for his own h ##yp ##oc ##ris ##y now , is indicative of his wish that the previous warning to himself by another and outside user ( on the kingdom of england ) is less ##ened in its effects . what a fuck ##tar ##d . \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
            "w ##ht the hell , are you insane or something ? if you had left me alone in the first place would we , dear god ! ! \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "\" : : : : : : : oh abs ##ol ##ut ##ly , i ' m still crying because i take the internet thing very seriously i have e - feelings . just like you have e - friends . what i shame , i still can ' t edit in wikipedia , right ? it ' s a zero ! \" \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "idiot fuck you , i had advanced tickets to see this thing because i wanted to see it so badly and your piece of shit ass ##es ruined it for me . \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
            "global apocalypse warning : rev ##ert another one of my edit ##s , and i will far ##t , causing a global ap ##oca ##ly ##pe and potential extinction of all species with a sense of smell ! \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "let me break it down for ya ' ll . murdering innocent men , women and children in cold blood is evil . and w ##th is up with ' operation cast lead ' ? ? ? ? weird ##ness . \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "muhammad was a murderer , rap ##ist , thief , slave trader , warm ##ong ##er and dirty pe ##do ##phile islam = nazi \n",
            "tensor([1, 0, 0, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 1.], device='cuda:0')\n",
            "\" thank you for your thanks . people do not seem to realise how children can be marked for life because of something that was said or done to them at a time of their life they will not even remember . children should be off limits & protected - no matter who their parents are . i did not do much on mv ##r , simply got involved with the word * ka ##put ##t * & the translation of some \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "\" a friend wu ##h ##wu ##zd ##at and hell ##bus . when ' s the wedding . now don ' t expect me to come , but don ' t worry , i ' ll watch you on the news , on the next 9 / 11 , ha ha ha ha ha ##aa ##aa ##aa . this time it will be a nuclear event . you can count on that . wu ##h ##wu ##zd ##at , can you feel \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "i find you people absolutely des ##pic ##able and disgusting that you allow b ##lat ##ant anti - semi ##tes to become administrators . may wikipedia burn in hell . \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "a question how big are your boo ##bs ? \n",
            "tensor([1, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "\" tag ##ging aw ##b first off , i use w ##p : aw ##b for a lot of this tag ##ging . i ' m not sure how familiar you are with it , but here are a couple of simple approaches . generate a list from category ( rec ##urs ##ive , user defined level ) choose a small number ( two or three ) convert to talk pages more - > prep ##end skip : if exists start alternately \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "but based on the wikipedia articles for cy ##borg and android , it appears to be both . talk \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "rm ##ing dod ##gy paragraph ? why is it dod ##gy ? could you please provide details of why you think it should be deleted , before del ##eti ##ng a whole paragraph contributed by fellow wikipedia ##ns ? it looks very np ##ov and references ad ##e ##quent ##ly , so it isn ' t one of the tod ##o ' s . there are other things to address , this will create yet more problems , keep the article as \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "er ##og ##uro nan ##sen ##su i wonder if the er ##og ##uro movement may have influenced the japanese military to per ##pet ##rate the rape of nan ##king . \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "i think that you ' re really stretching the definitions of the terms you ' re using . a top hit is media coverage ? then why does w ##p : music contain criteria 1 and 4 ? aren ' t they redundant ? and a book counts as media coverage ? not according to mass media . you ' re proposed criteria allow articles to be deleted which clearly pass one or more of w ##p : music ' s 7 \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "i ' m a total ni ##gger ##cock ##su ##cking fa ##gg ##ot . \n",
            "tensor([1, 0, 1, 0, 1, 1], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 1.], device='cuda:0')\n",
            "de ##grass ##i season 8 de ##grass ##i the new season fucking sucks so much . . . . they ##ve turned it into a fucking rein ##ac ##ment of laguna beach or some other mtv bullshit fucking show and seriously i won ##t be any fucking surprised if they just cancel the goddamn show after this stupid ass season . . . \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
            "\" : : : john strange ' s own nut ##jo ##b words : \" \" but in view of the lower limit for the existence of cap ##ht ##or / ke ##ft ##iu i would hesitate to identify in with crete , if there is nothing which definitely warrant ##s such an identification . \" \" too bad for him that cr ##eta ##n city ##name ##s following k ##ft ##i ##w are carved in stone during am ##en ##hot ##ep \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "how dare you yank the english language states that sul ##ph ##ur , the element with the symbol s , should be sp ##elt with a ph . if you want to use american english , then use your own wikipedia section . foreigners may well be confused if they look at the ' english ' wikipedia page as they would see incorrect grammar and spelling . alex par ##fi ##tt \n",
            "tensor([1, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "virgin my only warning ? you ' ll block me ? well f * ck off . you probably get off from warning people on wikipedia , don ' t you ? i bet you ' re still a virgin , f * ck ##ing homo . as for your warning , shove it up your ass . and f * ck you ! \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
            "inactive how long should someone not appear / compete until they ' re considered inactive ? i think vito should put on the inactive list . \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "for reference ' s sake the world council of churches ' statement ( baptism , eu ##cha ##rist , ministry ) : http : / / www . wc ##c - coe . org / wc ##c / what / faith / be ##m ##3 . html # iv might be helpful as this page is revised . . . i ' m going to start watching it , and if time permits , i ' ll take a crack at some \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "consensus # consensus - building in talk pages \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "\" thinking about this a bit more - it really seems you have it in for me . i know i keep mentioning ve ##ri ##fia ##ble sources , and it can be a pain . but i am simply thinking about this from the point of view of fa ##c . at fa ##c the citation you added would be questioned . so , that ' s not my decision . but also , it wouldn ' t surprise me if \n",
            "tensor([0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "' ' ' well guess what ? ! you are all ' ' ' ' ' ' fu ##king di ##ks ! ' ' ' ' ' ' ha ##ha ##ha ##ha ##ha ##ha ##ha ' ' ' ' ' ' ha ##ha ##ha ##ha ##ha ##ha ##ha ##ha ##ha ##ha ##ha ##aha ##ha ' ' ' ' ' ' ha ##hh ##aha ##aha ! ! ! ! ! ! ! ! ! ! su ##kers ! ! ' ' ' ' \n",
            "tensor([1, 0, 1, 0, 1, 0], dtype=torch.int32)\n",
            "tensor([1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
            "my ip is dynamic and my penis is 10 inches long \n",
            "tensor([1, 0, 1, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1., 0., 1., 0., 0., 0.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpm4phr6aFDd",
        "colab_type": "code",
        "outputId": "2f927b79-fca5-4a12-9b5c-42940ee2d0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(features))\n",
        "print(len(prediction))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC7xkeC9cpoc",
        "colab_type": "code",
        "outputId": "d87d4a0f-645c-4927-abf0-6a1e0e308228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## test on real kaggle test set\n",
        "\n",
        "testdata_path = '/content/drive/My Drive/Colab Notebooks/jigsaw/test/'\n",
        "ori_testdf = pd.read_csv(testdata_path + 'test.csv')\n",
        "\n",
        "\n",
        "\n",
        "print(len(ori_testdf)) #153164\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUTPjBHYeIBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_path = '/content/drive/My Drive/Colab Notebooks/jigsaw/test_labels/'\n",
        "labeldf = pd.read_csv(label_path + 'test_labels.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7dZ998GeOMA",
        "colab_type": "code",
        "outputId": "f724f1f5-03e2-4cb6-e33c-84862569e9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(labeldf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk-KsZO4eQsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_index = labeldf[labeldf['toxic']!=-1].index.tolist()\n",
        "\n",
        "data_for_pred = ori_testdf.iloc[correct_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphCqYF0xedf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdf = data_for_pred.drop(['id'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQGRAhJ3zSCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split1, split2, split3 = testdf[:5000].values, testdf[20000:25000].values, testdf[25000:30000].values\n",
        "\n",
        "split1_dataset = ToxicDataset(split1, 84) \n",
        "split1_dataloader = DataLoader(split1_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "split2_dataset = ToxicDataset(split2, 84)\n",
        "split2_dataloader = DataLoader(split2_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "split3_dataset = ToxicDataset(split3, 84)\n",
        "split3_dataloader = DataLoader(split3_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr92k5zQqlbx",
        "colab_type": "code",
        "outputId": "459b3cea-9100-4fe2-d54c-1397b3cffcb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "split1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Thank you for understanding. I think very highly of you and would not revert without discussion.'],\n",
              "       [':Dear god this site is horrible.'],\n",
              "       ['\"::: Somebody will invariably try to add Religion?  Really??  You mean, the way people have invariably kept adding \"\"Religion\"\" to the Samuel Beckett infobox?  And why do you bother bringing up the long-dead completely non-existent \"\"Influences\"\" issue?  You\\'re just flailing, making up crap on the fly. \\n ::: For comparison, the only explicit acknowledgement in the entire Amos Oz article that he is personally Jewish is in the categories!    \\n\\n \"'],\n",
              "       ...,\n",
              "       ['\" \\n\\n :Casaforra... WHO HAS EVER DENIED VALENCIAN OR MAJORCAN TO BE DIFFERENT FROM CATALAN???? WHO???? NO ONE! You\\'re so obsessed with your catalan-countries that you don\\'t take the time to read others comments. What we only say is that people from valencia call what they speak valencian and people from majorca call what they speak majorcan. You agreed on that. In andalusia no one will say when asked that he speaks \"\"andalú\"\"... They will say spanish... But ask someone from valencia or from majorca what they speak... You\\'ll see the difference. Oh and BTW, if you\\'re not \"\"going to change anything, since they all are dialects of Catalan\"\" at least, (and say this to your colleagues), let other people do it, without erasing, undoing or reverting on your part. If we explain that the language spoken in Valencia is called by valencians \"\"Valencian\"\", don\\'t change it. You see my point?\"'],\n",
              "       [':::The big bang fairy tale has retarded by a hundred years real astronomy.'],\n",
              "       ['. I pretty much genuinely hate him as an individual at this point']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-7AaKDWtXM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the first 5000 comments\n",
        "\n",
        "data = split1_dataloader\n",
        "\n",
        "actual, predictions = [], []\n",
        "with torch.no_grad():\n",
        "    for features, targets in data:\n",
        "        features = features.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        scores, attentions = model(features)\n",
        "        sigmoid_out = torch.sigmoid(scores)\n",
        "        prediction = torch.as_tensor(sigmoid_out > 0.5, dtype=torch.int32)\n",
        "\n",
        "        #print(features)\n",
        "        #print(targets)\n",
        "        for i, feat in enumerate(features):\n",
        "          #print(features[i])\n",
        "          #print(prediction[i])\n",
        "          #print(prediction[i].view(-1).tolist())\n",
        "          predictions.append(prediction[i].view(-1).tolist())\n",
        "\n",
        "\n",
        "        #print(prediction.view(-1).tolist())\n",
        "        #predictions.extend(prediction.view(-1).tolist())\n",
        "        #actual.extend(targets.long().view(-1).tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unvNqKEla6eG",
        "colab_type": "code",
        "outputId": "04f70cf4-1dbe-495d-c9a3-75e42126630a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOlC3UobTZZ",
        "colab_type": "code",
        "outputId": "f8b5950f-0bc7-4548-ec77-870a85a84eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(correct_index)\n",
        "label_5000 = [ind for ind in correct_index if ind < 5000]\n",
        "len(label_5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7oVcOIqbkGx",
        "colab_type": "code",
        "outputId": "1aa46cc8-016e-4975-ded5-6ed5291520b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred5000_df=pd.DataFrame(predictions)\n",
        "pred5000_df\n",
        "\n",
        "pred5000_for_f1 = pred5000_df.iloc[label_5000]\n",
        "\n",
        "preds = []\n",
        "for i in range(len(pred5000_for_f1)):\n",
        "  preds.extend(pred5000_for_f1.iloc[i].tolist())\n",
        "\n",
        "len(preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZ_dwsKb9hB",
        "colab_type": "code",
        "outputId": "8ba94870-b9cf-49a3-8b33-1d18f02c3ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(pred5000_for_f1) #2069\n",
        "\n",
        "actual_5000=labeldf[labeldf['toxic']!=-1].iloc[label_5000]\n",
        "actual_5000_noid = actual_5000.drop(columns=[\"id\"])\n",
        "\n",
        "actual_f1 = []\n",
        "for i in range(len(actual_5000_noid)):\n",
        "  actual_f1.extend(actual_5000_noid.iloc[i].tolist())\n",
        "\n",
        "len(actual_f1) #2069×6 - 12414\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iu2xqXVde60",
        "colab_type": "code",
        "outputId": "ef5da090-9488-428d-c3dc-cf96f25964e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "actual_5000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>000663aff0fffc80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>000844b52dee5f3f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>000a02d807ae0254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>000bf0a9894b2807</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>000c9b92318552d1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12029</th>\n",
              "      <td>1435bb7803d32a30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12035</th>\n",
              "      <td>14384ee62f85e67a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12036</th>\n",
              "      <td>143866f454ded075</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12040</th>\n",
              "      <td>14397283843e28c0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12043</th>\n",
              "      <td>1439e35a4edb4fbc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2069 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "16     000663aff0fffc80      0             0  ...       0       0              0\n",
              "19     000844b52dee5f3f      0             0  ...       0       0              0\n",
              "26     000a02d807ae0254      0             0  ...       0       0              0\n",
              "29     000bf0a9894b2807      0             0  ...       0       0              0\n",
              "31     000c9b92318552d1      0             0  ...       0       0              0\n",
              "...                 ...    ...           ...  ...     ...     ...            ...\n",
              "12029  1435bb7803d32a30      0             0  ...       0       0              0\n",
              "12035  14384ee62f85e67a      0             0  ...       0       0              0\n",
              "12036  143866f454ded075      0             0  ...       0       0              0\n",
              "12040  14397283843e28c0      0             0  ...       0       0              0\n",
              "12043  1439e35a4edb4fbc      0             0  ...       0       0              0\n",
              "\n",
              "[2069 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xlATt7c6gv",
        "colab_type": "code",
        "outputId": "9fae3d6c-db15-4e26-81b0-b2a350381b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Macro F1 Score', f1_score(actual_f1, preds, average = 'macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro F1 Score 0.7846581091598825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSKF1WWcfW2V",
        "colab_type": "code",
        "outputId": "015c0a37-cfac-452e-c6e3-6e19baf070af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# check full test data\n",
        "\n",
        "fulltest_dataset = ToxicDataset(testdf.values, 84) \n",
        "fulltest_dataloader = DataLoader(fulltest_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "data = fulltest_dataloader\n",
        "\n",
        "actual, predictions = [], []\n",
        "with torch.no_grad():\n",
        "    for features, targets in data:\n",
        "        features = features.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        scores, attentions = model(features)\n",
        "        sigmoid_out = torch.sigmoid(scores)\n",
        "        prediction = torch.as_tensor(sigmoid_out > 0.5, dtype=torch.int32)\n",
        "\n",
        "        #print(features)\n",
        "        #print(targets)\n",
        "        for i, feat in enumerate(features):\n",
        "          #print(features[i])\n",
        "          #print(prediction[i])\n",
        "          #print(prediction[i].view(-1).tolist())\n",
        "          predictions.append(prediction[i].view(-1).tolist())\n",
        "\n",
        "print(len(predictions))\n",
        "\n",
        "pred_df=pd.DataFrame(predictions)\n",
        "\n",
        "preds = []\n",
        "for i in range(len(pred_df)):\n",
        "  preds.extend(pred_df.iloc[i].tolist())\n",
        "\n",
        "print(len(preds))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63978\n",
            "383868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3bI_2gSgTwM",
        "colab_type": "code",
        "outputId": "ed38117d-fd2e-4550-8b29-b603f9290938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "actual_df=labeldf[labeldf['toxic']!=-1]\n",
        "actual_df_noid = actual_df.drop(columns=[\"id\"])\n",
        "\n",
        "actual_f1 = []\n",
        "for i in range(len(actual_df_noid)):\n",
        "  actual_f1.extend(actual_df_noid.iloc[i].tolist())\n",
        "\n",
        "len(actual_f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "383868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COx1-x_cgLWd",
        "colab_type": "code",
        "outputId": "88d0dbe1-a715-4c27-ecaa-4de0bbde7447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Macro F1 Score', f1_score(actual_f1, preds, average = 'macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro F1 Score 0.7881645102550523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV8c1gnXkINh",
        "colab_type": "code",
        "outputId": "918414f4-d551-491f-e988-be9dc5b85ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "ori_testdf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                                       comment_text\n",
              "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3       00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4       00017695ad8997eb          I don't anonymously edit articles at all.\n",
              "...                  ...                                                ...\n",
              "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
              "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
              "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
              "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
              "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...\n",
              "\n",
              "[153164 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Im0eiudfaR",
        "colab_type": "code",
        "outputId": "c97efb04-5052-4cec-9dcb-a7d5ddbaa11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## for kaggle submission -- only sigmoid values are needed \n",
        "## So instead of the 1 or 0 you have to just use the sigmoid values which are essentially probabilities for every label\n",
        "\n",
        "\n",
        "testdf = ori_testdf.drop(['id'], axis = 1)\n",
        "\n",
        "fulltest_dataset = ToxicDataset(testdf.values, 84) \n",
        "fulltest_dataloader = DataLoader(fulltest_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "data = fulltest_dataloader\n",
        "\n",
        "actual, predictions = [], []\n",
        "with torch.no_grad():\n",
        "    for features, targets in data:\n",
        "        features = features.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        scores, attentions = model(features)\n",
        "        sigmoid_out = torch.sigmoid(scores)\n",
        "        #print(sigmoid_out)\n",
        "        #prediction = torch.as_tensor(sigmoid_out > 0.5, dtype=torch.int32)\n",
        "\n",
        "        #print(features)\n",
        "        #print(targets)\n",
        "        for i, feat in enumerate(features):\n",
        "          #print(features[i])\n",
        "          #print(prediction[i])\n",
        "          #print(prediction[i].view(-1).tolist())\n",
        "          predictions.append(sigmoid_out[i].view(-1).tolist())\n",
        "\n",
        "print(len(predictions))\n",
        "\n",
        "pred_df=pd.DataFrame(predictions)\n",
        "\n",
        "preds = []\n",
        "for i in range(len(pred_df)):\n",
        "  preds.extend(pred_df.iloc[i].tolist())\n",
        "\n",
        "print(len(preds))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164\n",
            "918984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1StKr-CekDFi",
        "colab_type": "code",
        "outputId": "46fe40b9-a70e-4c90-ec15-5cf04c63e4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(pred_df)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXA4fa2_lDNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df['id']= ori_testdf['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_WH_S8Emwkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pred_df[['id',0,1,2,3,4,5]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw90IhPmlRp5",
        "colab_type": "code",
        "outputId": "7aa397e4-f55f-475f-c062-19cd2155e0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.998539</td>\n",
              "      <td>0.424346</td>\n",
              "      <td>0.985993</td>\n",
              "      <td>0.054958</td>\n",
              "      <td>0.965682</td>\n",
              "      <td>0.118837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.005951</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.003635</td>\n",
              "      <td>0.003572</td>\n",
              "      <td>0.002988</td>\n",
              "      <td>0.003278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.010530</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.002599</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.002375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>0.003854</td>\n",
              "      <td>0.003540</td>\n",
              "      <td>0.004133</td>\n",
              "      <td>0.003304</td>\n",
              "      <td>0.004066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.009394</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>0.003643</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>0.002803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         0         1         2         3         4         5\n",
              "0  00001cee341fdb12  0.998539  0.424346  0.985993  0.054958  0.965682  0.118837\n",
              "1  0000247867823ef7  0.005951  0.003443  0.003635  0.003572  0.002988  0.003278\n",
              "2  00013b17ad220c46  0.010530  0.002916  0.004239  0.002599  0.003059  0.002375\n",
              "3  00017563c3f7919a  0.004761  0.003854  0.003540  0.004133  0.003304  0.004066\n",
              "4  00017695ad8997eb  0.009394  0.002896  0.003643  0.003736  0.002846  0.002803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxAIhXP6lTzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df.columns = [\"id\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRFnJgeulnwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df.to_csv('kaggle_submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GshbZVPhnWzy",
        "colab_type": "code",
        "outputId": "b3169851-4bcd-4c9f-e46c-6cd788926e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153164, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdL9guuCnZdu",
        "colab_type": "code",
        "outputId": "988ada06-95fa-4d3b-c0d0-f38aadb2a258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pd.read_csv('kaggle_submission.csv').head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.998539</td>\n",
              "      <td>0.424346</td>\n",
              "      <td>0.985993</td>\n",
              "      <td>0.054958</td>\n",
              "      <td>0.965682</td>\n",
              "      <td>0.118837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.005951</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.003635</td>\n",
              "      <td>0.003572</td>\n",
              "      <td>0.002988</td>\n",
              "      <td>0.003278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.010530</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.002599</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.002375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>0.003854</td>\n",
              "      <td>0.003540</td>\n",
              "      <td>0.004133</td>\n",
              "      <td>0.003304</td>\n",
              "      <td>0.004066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.009394</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>0.003643</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>0.002803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     toxic  severe_toxic  ...    threat    insult  identity_hate\n",
              "0  00001cee341fdb12  0.998539      0.424346  ...  0.054958  0.965682       0.118837\n",
              "1  0000247867823ef7  0.005951      0.003443  ...  0.003572  0.002988       0.003278\n",
              "2  00013b17ad220c46  0.010530      0.002916  ...  0.002599  0.003059       0.002375\n",
              "3  00017563c3f7919a  0.004761      0.003854  ...  0.004133  0.003304       0.004066\n",
              "4  00017695ad8997eb  0.009394      0.002896  ...  0.003736  0.002846       0.002803\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uChUS6Q4npeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}